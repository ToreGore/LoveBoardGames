{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from BggHelper.ipynb\n",
      "importing Jupyter notebook from BggDbGetter.ipynb\n",
      "importing Jupyter notebook from BggDbScraper.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import import_ipynb\n",
    "import pandas as pnd\n",
    "import BggHelper as BH\n",
    "import BggDbGetter as BDG\n",
    "import BggDbScraper as BDS\n",
    "from gensim.models import Word2Vec\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect\n",
    "from tqdm.notebook import tqdm\n",
    "from iso_language_codes import *\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from boardgamegeek import BoardGameGeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cicero:\n",
    "    def __init__(self, glossa):\n",
    "        self._glossa = glossa\n",
    "    def clean_stemming(self, field):\n",
    "        self._glossa = ((self._glossa.useless_langs_remover(field)).stopwords_removal(field)).stemming(field)\n",
    "        #return self._glossa.get_df()\n",
    "        return self\n",
    "    def clean_lemming(self, field):\n",
    "        self._glossa = ((self._glossa.useless_langs_remover(field)).stopwords_removal(field)).lemming(field)\n",
    "        #return self._glossa.get_df()\n",
    "        return self\n",
    "    def eng_lemming(self, field):\n",
    "        self._glossa = (self._glossa.stopwords_removal(field)).lemming(field)\n",
    "        #return self._glossa.get_df()\n",
    "        return self\n",
    "    def overall_occurrences(self, field, min_granularity = 1, reverse = True):\n",
    "        bag = dict()\n",
    "        col = self._glossa.get_df()[field]\n",
    "        # For each word in a row count all occurrences in all rows\n",
    "        for row in col:\n",
    "            b = set(row)\n",
    "            for item in b:\n",
    "                if item.isalpha():\n",
    "                    if item in bag:\n",
    "                        bag[item] = bag[item] + row.count(item)\n",
    "                    else:\n",
    "                        bag[item] = row.count(item)\n",
    "        return sorted(bag.items(), key=lambda x: x[0], reverse=reverse)\n",
    "    def stemma_lemma(self, field):\n",
    "        self._glossa = ((self._glossa.useless_langs_remover(field)).stopwords_removal(field)).lemming(field).stemming(field)\n",
    "        #return self._glossa.get_df()\n",
    "        return self\n",
    "    def word2vec_train(self, fields, dimensions=100, sg=0):\n",
    "        rows = self._glossa.get_interesting_fields(fields)\n",
    "        #print(len(rows))\n",
    "        for i in range(len(rows)):\n",
    "            rows[i].append(self._glossa.get_df()[\"name\"][i])\n",
    "        model = Word2Vec(rows, min_count=1, size=dimensions, workers=3, window=3, sg=0)\n",
    "        return model, rows\n",
    "    def get_df(self):\n",
    "        return self._glossa.get_df()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
